{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2744f214",
   "metadata": {},
   "source": [
    "# Prompt engineering for CoNNL-U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8e9402",
   "metadata": {},
   "source": [
    "Here's an example API query. To run this yourself you need to run `export OPENAI_API_KEY_TREEBANKS=\"your api key\"` in the terminal with the API key from your own OpenAI account. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208ad2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [03:00, 36.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tThetta\tthetta\tPRON\t_\tCase=Nom|Gender=Neut|Number=Sing|PronType=Dem\t4\tnsubj\t4:nsubj\t_\n",
      "2\tÃ¤r\tvara\tAUX\t_\tMood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t4\tcop\t4:cop\t_\n",
      "3\tinte\tinte\tPART\t_\tPolarity=Neg\t2\tneg\t2:neg\t_\n",
      "4\tbegynnilsen\tbegynnilsen\tNOUN\t_\tCase=Nom|Definite=Def|Gender=Com|Number=Sing\t0\troot\t0:root\t_\n",
      "5\taff\taff\tADP\t_\tAdpType=Prep\t10\tcase\t10:case\t_\n",
      "6\tJesu\tJesu\tPROPN\t_\tCase=Gen|Gender=Masc|Number=Sing\t7\tflat\t7:flat|10:nmod:poss\t_\n",
      "7\tChristi\tChristi\tPROPN\t_\tCase=Gen|Gender=Masc|Number=Sing\t10\tnmod:poss\t10:nmod:poss\t_\n",
      "8\tgudz\tgudz\tPROPN\t_\tCase=Gen|Gender=Masc|Number=Sing\t9\tnmod:poss\t9:nmod:poss|10:nmod:poss\t_\n",
      "9\tsons\tsons\tNOUN\t_\tCase=Gen|Gender=Masc|Number=Sing\t10\tnmod:poss\t10:nmod:poss\t_\n",
      "10\teuangelio\teuangelio\tNOUN\t_\tCase=Nom|Gender=Neut|Number=Sing\t4\tnmod\t4:nmod\t_\n",
      "11\t.\t.\tPUNCT\t_\t_\t4\tpunct\t4:punct\t_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from src.pipeline import pipeline\n",
    "\n",
    "input_sentence = \"Thetta Ã¤r inte begynnilsen aff Jesu Christi gudz sons euangelio.\"\n",
    "conllu = pipeline(input_sentence, model=\"gpt-5-mini-2025-08-07\")\n",
    "print(conllu)\n",
    "\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "outname = f\"output/parsed_{input_sentence.split()[0]}.conllu\"\n",
    "with open(outname, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(conllu + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d4b9b",
   "metadata": {},
   "source": [
    "We can quickly check validity using the python `conllu` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbfbe0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoNNL-U valid ðŸ¥³\n"
     ]
    }
   ],
   "source": [
    "from src.pipeline import is_valid_conllu\n",
    "\n",
    "#outname = f\"output/parsed_{input_sentence.split()[0]}.conllu\"\n",
    "outname = f\"output/parsed.conllu\"\n",
    "validity = is_valid_conllu(outname)\n",
    "if validity:\n",
    "    print(\"CoNNL-U valid ðŸ¥³\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb02ed",
   "metadata": {},
   "source": [
    "## The Batch API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892f2400",
   "metadata": {},
   "source": [
    "Before running on a large file from Svensk diakronisk korpus, you can estimate the cost roughly (based on using the Batch API, which is 50% cheaper). Caveat emptor, though, your credit card is on its own! To be absolutely safe, you can set a limit in your project settings.\n",
    "\n",
    "The algorithm counts tokens from all `# text =` fields in the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67c0e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input tokens: 79705\n",
      "Approximate input cost: $0.009963\n",
      "Approximate output cost: $0.034200\n",
      "Approximate total cost: $0.044163\n"
     ]
    }
   ],
   "source": [
    "from src.count_tokens import count_total_tokens_and_cost\n",
    "\n",
    "path = \"data/svediakorp-rel108-Mar26SLundversion.tsv\"\n",
    "tokens, input_cost, output_cost = count_total_tokens_and_cost(path)\n",
    "print(f\"Total input tokens: {tokens}\")\n",
    "print(f\"Approximate input cost: ${input_cost:.6f}\")\n",
    "print(f\"Approximate output cost: ${output_cost:.6f}\")\n",
    "print(f\"Approximate total cost: ${input_cost + output_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a13449a",
   "metadata": {},
   "source": [
    "Irritatingly enough, we have to make one batch jsonl per task, submit it, and then incorporate the results into the jsonl of the next task.\n",
    "\n",
    "For most sentences, conllu table output seems to not be much more than 2k tokens, but there are of course obscene exceptions, especially in premodern texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cea2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069304aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prepare_task1_responses_batch_jsonl] wrote 171 requests -> batches/batch_task1.jsonl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.batching import prepare_task1_responses_batch_jsonl\n",
    "\n",
    "prepare_task1_responses_batch_jsonl(\"data/svediakorp-rel108-Mar26SLundversion.conllu\", \"batches/batch_task1.jsonl\", model=\"gpt-5-mini-2025-08-07\", max_output_tokens=8192)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
